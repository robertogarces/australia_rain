{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bb9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "sys.path.append('../')\n",
    "\n",
    "from config.paths import CONFIG_PATH, ARTIFACTS_PATH, MODELS_PATH\n",
    "from utils.file_management import load_config\n",
    "from utils.preprocessors import (\n",
    "    binary_mapper,\n",
    "    assign_season\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae102d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/inference_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f5dcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:31:55,343 - utils.file_management - INFO - Loading yaml file from /Users/robertogarces/data-science/projects/australia-rain/australia-rain/config/settings.yaml\n",
      "2025-05-27 15:31:55,349 - utils.file_management - INFO - Loading yaml file from /Users/robertogarces/data-science/projects/australia-rain/australia-rain/config/features.yaml\n"
     ]
    }
   ],
   "source": [
    "config_path = CONFIG_PATH / \"settings.yaml\"\n",
    "config = load_config(config_path)\n",
    "features_path = CONFIG_PATH / \"features.yaml\"\n",
    "features = load_config(features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1057172",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_params = config['preprocessing_parameters']\n",
    "wind_mapping = config['wind_mapping']\n",
    "\n",
    "target = features['target']\n",
    "features_to_map = features['features_to_map']\n",
    "num_features = features['numeric_features']\n",
    "cat_features = features['categorical_features']\n",
    "features_with_outliers = features['features_with_outliers']\n",
    "model_features = features['model_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ae8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_drop = df.shape[0]\n",
    "df.dropna(subset=[target], inplace=True)\n",
    "after_drop = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7971d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = binary_mapper(df, features_to_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "807d4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "if df['Date'].isnull().any():\n",
    "    n_null_dates = df['Date'].isnull().sum()\n",
    "    df = df.dropna(subset=['Date'])\n",
    "df['Month'] = df['Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f0965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/ncxpj9h14r9g4p_hwtl94y400000gn/T/ipykernel_88796/61935337.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('Missing', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dropped_correlated_features_path = ARTIFACTS_PATH / 'dropped_correlated_features.json'\n",
    "with open(dropped_correlated_features_path, 'r', encoding='utf-8') as file:\n",
    "    dropped_correlated_features = json.load(file)\n",
    "df.drop(dropped_correlated_features, axis=1, inplace=True)\n",
    "\n",
    "for col in cat_features:\n",
    "    if col in df.columns:\n",
    "        df[col].fillna('Missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b21fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_group_medians_path = ARTIFACTS_PATH / 'imputation_group_medians.json'\n",
    "with open(imputation_group_medians_path, 'r', encoding='utf-8') as file:\n",
    "    imputation_group_medians = json.load(file)\n",
    "\n",
    "def apply_group_median_imputation(df, group_medians, features, group_cols=['Month', 'Location'], fallback=-1):\n",
    "    \"\"\"\n",
    "    Impute missing values in specified columns using precomputed group-level medians.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with missing values.\n",
    "        group_medians (dict): Dict con medians per group in format {'Month|Location': {feature: value}}.\n",
    "        features (list): Features to impute.\n",
    "        group_cols (list): Group by features (default=['Month', 'Location']).\n",
    "        fallback (float): Value to use if there's not group median.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con los valores imputados.\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    valid_features = [f for f in features if f in df.columns]\n",
    "\n",
    "    if not valid_features:\n",
    "        return df_imputed\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        key = '|'.join(map(str, [row[col] for col in group_cols]))\n",
    "        for feature in valid_features:\n",
    "            if pd.isna(row[feature]):\n",
    "                value = group_medians.get(key, {}).get(feature, fallback)\n",
    "                df_imputed.at[idx, feature] = value\n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cceb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_group_median_imputation(df, imputation_group_medians, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e0c50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['WindGustDir', 'WindDir9am', 'WindDir3pm']:\n",
    "    if col in df.columns:\n",
    "        mapped_col = f\"{col}_deg\"\n",
    "        df[mapped_col] = df[col].map(wind_mapping)\n",
    "        n_missing = df[mapped_col].isnull().sum()\n",
    "\n",
    "df['Season'] = df['Month'].apply(assign_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23b4a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = ARTIFACTS_PATH / 'label_encoders.pkl'\n",
    "with open(encoder_path, 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "def apply_label_encoders(df, encoders, fallback_value=-1):\n",
    "    \"\"\"\n",
    "    Aplica múltiples LabelEncoders a un DataFrame, manejando categorías desconocidas.\n",
    "\n",
    "    Parámetros:\n",
    "        df (pd.DataFrame): DataFrame de entrada.\n",
    "        encoders (dict): Diccionario {columna: LabelEncoder}.\n",
    "        fallback_value (int): Valor para categorías no vistas.\n",
    "\n",
    "    Retorna:\n",
    "        pd.DataFrame: DataFrame con columnas codificadas.\n",
    "    \"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    for col, encoder in encoders.items():\n",
    "        if col not in df_encoded.columns:\n",
    "            continue\n",
    "\n",
    "        known_classes = set(encoder.classes_)\n",
    "\n",
    "        def encode_value(val):\n",
    "            if pd.isna(val) or val not in known_classes:\n",
    "                return fallback_value\n",
    "            return encoder.transform([val])[0]\n",
    "\n",
    "        df_encoded[col] = df_encoded[col].apply(encode_value)\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efbb2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_label_encoders(df, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a7dd1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e44da4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[model_features].drop(target, axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64512b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = MODELS_PATH / 'lgbm.joblib'\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b52c7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.662527865530507, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.662527865530507\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8995018083363232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8995018083363232\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71d6786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       759\n",
      "           1       0.77      0.57      0.65       224\n",
      "\n",
      "    accuracy                           0.86       983\n",
      "   macro avg       0.82      0.76      0.78       983\n",
      "weighted avg       0.86      0.86      0.86       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y, preds)\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "print(classification_report(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80d096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8f143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b14bcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aus_rain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
