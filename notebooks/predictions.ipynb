{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c07bb9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "sys.path.append('../')\n",
    "\n",
    "from config.paths import RAW_DATA_PATH, PROCESSED_DATA_PATH, CONFIG_PATH, ARTIFACTS_PATH, MODELS_PATH\n",
    "from utils.config_loader import load_config\n",
    "from utils.preprocessors import (\n",
    "    binary_mapper,\n",
    "    filter_outliers_by_percentile,\n",
    "    remove_highly_correlated_features,\n",
    "    impute_median_by_group,\n",
    "    fill_missing_categories,\n",
    "    label_encoder,\n",
    "    assign_season\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae102d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/inference_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f5dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = CONFIG_PATH / \"settings.yaml\"\n",
    "config = load_config(config_path)\n",
    "features_path = CONFIG_PATH / \"features.yaml\"\n",
    "features = load_config(features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1057172",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_params = config['preprocessing_parameters']\n",
    "wind_mapping = config['wind_mapping']\n",
    "\n",
    "target = features['target']\n",
    "features_to_map = features['features_to_map']\n",
    "num_features = features['numeric_features']\n",
    "cat_features = features['categorical_features']\n",
    "features_with_outliers = features['features_with_outliers']\n",
    "model_features = features['model_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ae8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_drop = df.shape[0]\n",
    "df.dropna(subset=[target], inplace=True)\n",
    "after_drop = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7971d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = binary_mapper(df, features_to_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "807d4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "if df['Date'].isnull().any():\n",
    "    n_null_dates = df['Date'].isnull().sum()\n",
    "    df = df.dropna(subset=['Date'])\n",
    "df['Month'] = df['Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0fe7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = filter_outliers_by_percentile(df, features_with_outliers, pp_params['outliers_percentile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f99870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Botar las columnas que se botan por alta correlacion ---\n",
    "# Fill de missing cat values ---\n",
    "# Imputar num features ---\n",
    "# Wind dir mapping ---\n",
    "# Assing season ---\n",
    "# Encoding ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83407e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f0965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/ncxpj9h14r9g4p_hwtl94y400000gn/T/ipykernel_63870/61935337.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('Missing', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dropped_correlated_features_path = ARTIFACTS_PATH / 'dropped_correlated_features.json'\n",
    "with open(dropped_correlated_features_path, 'r', encoding='utf-8') as file:\n",
    "    dropped_correlated_features = json.load(file)\n",
    "df.drop(dropped_correlated_features, axis=1, inplace=True)\n",
    "\n",
    "for col in cat_features:\n",
    "    if col in df.columns:\n",
    "        df[col].fillna('Missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b21fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_group_medians_path = ARTIFACTS_PATH / 'imputation_group_medians.json'\n",
    "with open(imputation_group_medians_path, 'r', encoding='utf-8') as file:\n",
    "    imputation_group_medians = json.load(file)\n",
    "\n",
    "def apply_group_median_imputation(df, group_medians, features, group_cols=['Month', 'Location'], fallback=-1):\n",
    "    \"\"\"\n",
    "    Impute missing values in specified columns using precomputed group-level medians.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame con valores faltantes.\n",
    "        group_medians (dict): Diccionario con medianas por grupo en formato {'Month|Location': {feature: value}}.\n",
    "        features (list): Columnas a imputar.\n",
    "        group_cols (list): Columnas de agrupamiento (default=['Month', 'Location']).\n",
    "        fallback (float): Valor a usar si no hay mediana disponible para un grupo o feature.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con los valores imputados.\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    valid_features = [f for f in features if f in df.columns]\n",
    "\n",
    "    if not valid_features:\n",
    "        return df_imputed\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        key = '|'.join(map(str, [row[col] for col in group_cols]))\n",
    "        for feature in valid_features:\n",
    "            if pd.isna(row[feature]):\n",
    "                value = group_medians.get(key, {}).get(feature, fallback)\n",
    "                df_imputed.at[idx, feature] = value\n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cceb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_group_median_imputation(df, imputation_group_medians, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e0c50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['WindGustDir', 'WindDir9am', 'WindDir3pm']:\n",
    "    if col in df.columns:\n",
    "        mapped_col = f\"{col}_deg\"\n",
    "        df[mapped_col] = df[col].map(wind_mapping)\n",
    "        n_missing = df[mapped_col].isnull().sum()\n",
    "\n",
    "df['Season'] = df['Month'].apply(assign_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23b4a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = ARTIFACTS_PATH / 'label_encoders.pkl'\n",
    "with open(encoder_path, 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "def apply_label_encoders(df, encoders, fallback_value=-1):\n",
    "    \"\"\"\n",
    "    Aplica múltiples LabelEncoders a un DataFrame, manejando categorías desconocidas.\n",
    "\n",
    "    Parámetros:\n",
    "        df (pd.DataFrame): DataFrame de entrada.\n",
    "        encoders (dict): Diccionario {columna: LabelEncoder}.\n",
    "        fallback_value (int): Valor para categorías no vistas.\n",
    "\n",
    "    Retorna:\n",
    "        pd.DataFrame: DataFrame con columnas codificadas.\n",
    "    \"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    for col, encoder in encoders.items():\n",
    "        if col not in df_encoded.columns:\n",
    "            continue\n",
    "\n",
    "        known_classes = set(encoder.classes_)\n",
    "\n",
    "        def encode_value(val):\n",
    "            if pd.isna(val) or val not in known_classes:\n",
    "                return fallback_value\n",
    "            return encoder.transform([val])[0]\n",
    "\n",
    "        df_encoded[col] = df_encoded[col].apply(encode_value)\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_label_encoders(df, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a7dd1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e44da4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[model_features].drop(target, axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64512b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = MODELS_PATH / 'lgbm.joblib'\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b52c7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6980742078570433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6980742078570433\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8108587720848638, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8108587720848638\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71d6786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       759\n",
      "           1       0.87      0.76      0.81       224\n",
      "\n",
      "    accuracy                           0.92       983\n",
      "   macro avg       0.90      0.86      0.88       983\n",
      "weighted avg       0.92      0.92      0.92       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y, preds)\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "print(classification_report(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80d096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8f143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b14bcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aus_rain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
